define({"0":{y:0,u:"../Content/A_LLM_Basics/LLM_Basics.htm",l:-1,t:"Large Language Model Basics",i:0.0185460227385021,a:"Large Language Model Basics Here is some general text for a topic. Replace this with your own content..."},"1":{y:0,u:"../Content/A_LLM_Basics/What_is_an_LLM.htm",l:-1,t:"What constitutes a LLM?",i:0.0185460227385021,a:"What constitutes a LLM? Here is some general text for a topic. Replace this with your own content."},"2":{y:0,u:"../Content/A_LLM_Basics/Pros_And_Cons.htm",l:-1,t:"Pros and Cons of Local and Cloud Based LLMs ",i:0.0185460227385021,a:"Pros and Cons of Local and Cloud Based LLMs  Here is some general text for a topic. Replace this with your own content."},"3":{y:0,u:"../Content/B_Getting_Started/Getting_Started.htm",l:-1,t:"Getting Started with text-generation-webui",i:0.0185460227385021,a:"Text-generation-webui  (known also as Oooba, after its creator, Ooobabooga) is a web UI for running LLMs locally. It\u0027s one of the major pieces of open source software used by AI hobbyists and professionals alike. This tutorial will teach you how to deploy a local text-generation-webui installation ..."},"4":{y:0,u:"../Content/B_Getting_Started/System_requirements.htm",l:-1,t:"System requirements",i:0.0343103440283402,a:"For the best experience, you will need the following: Dedicated NVIDIA or AMD graphics card, with at least 8GB of VRAM At least 16GB of RAM A modern processor, supporting AVX2 instructions. If your processor was bought after 2011, it almost definitely supports this standard. Generally speaking, the ..."},"5":{y:0,u:"../Content/B_Getting_Started/Download_and_setup.htm",l:-1,t:"Download and first-time setup",i:0.0477097675258901,a:"Downloading text-generation-webui is best accomplished by cloning the repository. You will need to download and install  GitHub Desktop  on your system. The process is straightforward and should only take a minute. Tip: If you are already familiar with Git, you may use it instead to clone the ..."},"6":{y:0,u:"../Content/B_Getting_Started/UI_and_basic_functionality.htm",l:-1,t:"UI overview and Basic Functionality",i:0.0590985243866929,a:"When you first run text-generation-webui and open the URL provided in the terminal window, you will see the application\u0027s main interface. Here are its main elements: Main toolbar: contains various tabs - most importantly Chat,  Parametersand Model Past chats: allows you to create a new chat, as well ..."},"7":{y:0,u:"../Content/C_Selecting_a_Model/Selecting_a_model.htm",l:-1,t:"Open-weight Models",i:0.0352901358421996,a:"Using open source LLMs allows for a large degree of freedom when it comes to picking an open-weight model that will best suit your needs. Companies like Mistral AI, Meta or Google have released open-weight models, and the open source community has fine-tuned them to suit a wide variety of needs. ..."},"8":{y:0,u:"../Content/C_Selecting_a_Model/Browsing_HF.htm",l:-1,t:"Browsing Hugging Face repositories",i:0.0335442192537067,a:"Hugging Face is a French-American AI company, which has developed many of the foundational technologies behind open-source machine learning - most notably the transformers library.  Hugging Face Hub  has become the go-to platform for sharing of models, finetunes, data sets and demos related to all ..."},"9":{y:0,u:"../Content/C_Selecting_a_Model/Model_size.htm",l:-1,t:"First model - size vs hardware capabilities",i:0.0470588530626137,a:"If you don\u0027t want to learn about the technical details of local LLMs and wish to skip to downloading and loading a model, feel free to skip ahead to a  list of recommended models. Tip: Refer to the  system requirements  section and decide on which method of loading the model you wish to use, if you ..."},"10":{y:0,u:"../Content/C_Selecting_a_Model/Model_formats.htm",l:-1,t:"GGUF model format",i:0.0318794744374456,a:"Machine learning is a dynamic field, and there are many standards and quantization formats, both current and already obsolete. For the sake of this guide, we will consider the most versatile of them - GGUF. Tip: Refer to the  system requirements  section and decide on which method of loading the ..."},"11":{y:0,u:"../Content/C_Selecting_a_Model/Recommended_first_models.htm",l:-1,t:"Recommended first models",i:0.0604264424435233,a:"This section contains pre-selected, simple models for those who wish to try text-generation-webui with minimal research. Tip: Refer to the  system requirements  section and decide on which method of loading the model you wish to use, if you haven\u0027t done so already. The models below will work with ..."},"12":{y:0,u:"../Content/D_Model_configuration/Model_configuration.htm",l:-1,t:"Model Configuration",i:0.0834568573277705,a:"To use a LLM with text-generation-webui, you first need to load it into your memory, and then configure it. Both of these processes are fairly simple and should only take you a minute. To start, you will need to learn about model parameters and context size. When ready, start by learning how to  ..."},"13":{y:0,u:"../Content/D_Model_configuration/Loading_model.htm",l:-1,t:"Loading the model",i:0.106227180636409,a:"Tip: Before following the steps in this section, remember to download a model and put it in the models folder in your text-generation-webui installation directory. Loading a model in text-generation-webui is simple. Launch the webui by double-clicking the start_windows.bat script in your main ..."},"14":{y:0,u:"../Content/D_Model_configuration/Model_parameters.htm",l:-1,t:"Model parameters",i:0.138914961757457,a:"Unlike online services such as ChatGPT, Gemma or Claude, local LLMs offer you the possibility of manually adjusting their parameters. You can make the AI\u0027s responses more or less random and predictable, change the output length and more. Instruction templates Instruction templates are a template for ..."},"15":{y:0,u:"../Content/D_Model_configuration/Generation_parameters.htm",l:-1,t:"Generation parameters",i:0.0185460227385021,a:"Generation parameters Delete this text and replace it with your own content."},"16":{y:0,u:"../Content/E_Chatting/Chatting.htm",l:-1,t:"Chatting",i:0.136623011912931,a:"Chatting Delete this text and replace it with your own content."},"17":{y:0,u:"../Content/E_Chatting/Basic_chats.htm",l:-1,t:"Basic chats",i:0.0185460227385021,a:"Basic chats Delete this text and replace it with your own content."},"18":{y:0,u:"../Content/E_Chatting/Characters.htm",l:-1,t:"Characters",i:0.0185460227385021,a:"Characters Delete this text and replace it with your own content."},"19":{y:0,u:"../Content/E_Chatting/API.htm",l:-1,t:"API",i:0.0185460227385021,a:"API Delete this text and replace it with your own content."},"20":{y:0,u:"../Content/F_Further_reading/Further_Reading.htm",l:-1,t:"Further reading",i:0.0185460227385021,a:"Further reading Delete this text and replace it with your own content."},"21":{y:0,u:"../Content/F_Further_reading/Alternative_software.htm",l:-1,t:"Software Alternatives",i:0.0185460227385021,a:"Software Alternatives Delete this text and replace it with your own content."},});