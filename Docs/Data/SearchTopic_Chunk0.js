define({"0":{y:0,u:"../Content/A_LLM_Basics/LLM_Basics.htm",l:-1,t:"Large Language Model Basics",i:0.01071716486631,a:"Large Language Model Basics Here is some general text for a topic. Replace this with your own content..."},"1":{y:0,u:"../Content/A_LLM_Basics/What_is_an_LLM.htm",l:-1,t:"What constitutes a LLM?",i:0.01071716486631,a:"What constitutes a LLM? Here is some general text for a topic. Replace this with your own content."},"2":{y:0,u:"../Content/A_LLM_Basics/Pros_And_Cons.htm",l:-1,t:"Pros and Cons of Local and Cloud Based LLMs ",i:0.01071716486631,a:"Pros and Cons of Local and Cloud Based LLMs  Here is some general text for a topic. Replace this with your own content."},"3":{y:0,u:"../Content/B_Getting_Started/Getting_Started.htm",l:-1,t:"Getting Started with text-generation-webui",i:0.01071716486631,a:"Text-generation-webui  (known also as Oooba, after its creator, Ooobabooga) is a web UI for running LLMs locally. It\u0027s one of the major pieces of open source software used by AI hobbyists and professionals alike. This tutorial will teach you how to deploy a local text-generation-webui installation ..."},"4":{y:0,u:"../Content/B_Getting_Started/System_requirements.htm",l:-1,t:"System requirements",i:0.0198267481235483,a:"For the best experience, you will need the following: At least 16GB of RAM A modern processor, supporting AVX2 instructions. If your processor was bought after 2011, it almost definitely supports this standard. Optional, but highly recommended: a dedicated NVIDIA or AMD graphics card, with at least ..."},"5":{y:0,u:"../Content/B_Getting_Started/Download_and_setup.htm",l:-1,t:"Download and first-time setup",i:0.0503956089160037,a:"Downloading text-generation-webui is best accomplished by cloning the repository. You will need to download and install  GitHub Desktop  on your system. The process is straightforward and should only take a minute. Tip: If you are already familiar with Git, you may use it instead to clone the ..."},"6":{y:0,u:"../Content/B_Getting_Started/UI_and_basic_functionality.htm",l:-1,t:"UI overview and Basic Functionality",i:0.0535500265968332,a:"When you first run text-generation-webui and open the URL provided in the terminal window, you will see the application\u0027s main interface. Here are its main elements: Main toolbar: contains various tabs used to navigate between screens - notably Chat,  Parametersand Model Past chats: allows you to ..."},"7":{y:0,u:"../Content/C_Selecting_a_Model/Selecting_a_model.htm",l:-1,t:"Open-weight Models",i:0.0487163815137417,a:"Using open source LLMs allows for a large degree of freedom when it comes to picking an open-weight model that will best suit your needs. Companies like Mistral AI, Meta or Google have released open-weight models, and the open source community has fine-tuned them to suit a wide variety of needs. ..."},"8":{y:0,u:"../Content/C_Selecting_a_Model/Browsing_HF.htm",l:-1,t:"Browsing Hugging Face repositories",i:0.0314199801546583,a:"Hugging Face is a French-American AI company, which has developed many of the foundational technologies behind open-source machine learning - most notably the transformers library.  Hugging Face Hub  has become the go-to platform for sharing of models, finetunes, data sets and demos related to all ..."},"9":{y:0,u:"../Content/C_Selecting_a_Model/Model_size.htm",l:-1,t:"First model - size vs hardware capabilities",i:0.0374248835466,a:"If you don\u0027t want to learn about the technical details of local LLMs and wish to skip to downloading and loading a model, feel free to skip ahead to a  list of recommended models. Tip: Refer to the  system requirements  section and decide on which method of loading the model you wish to use, if you ..."},"10":{y:0,u:"../Content/C_Selecting_a_Model/Model_formats.htm",l:-1,t:"GGUF model format - downloading a model",i:0.044146952626639,a:"Machine learning is a dynamic field, and there are many standards and quantization formats, both current and already obsolete. For the sake of this guide, we will consider the most versatile of them - GGUF. Tip: Refer to the  system requirements  section and decide on which method of loading the ..."},"11":{y:0,u:"../Content/C_Selecting_a_Model/Recommended_first_models.htm",l:-1,t:"Recommended first models",i:0.0607843101709899,a:"This section contains pre-selected, simple models for those who wish to try text-generation-webui with minimal research. Tip: Refer to the  system requirements  section and decide on which method of loading the model you wish to use, if you haven\u0027t done so already. The models below will work with ..."},"12":{y:0,u:"../Content/D_Model_configuration/Model_configuration.htm",l:-1,t:"Model Configuration",i:0.0811456597089169,a:"To use a LLM with text-generation-webui, you first need to load it into your memory, and then configure it. Both of these processes are fairly simple and should only take you a minute. To start, you will need to learn about model parameters and context size. When ready, start by learning how to  ..."},"13":{y:0,u:"../Content/D_Model_configuration/Loading_model.htm",l:-1,t:"Loading the model",i:0.127196702909939,a:"Tip: Before following the steps in this section, remember to download a model and put it in the models folder in your text-generation-webui installation directory. Loading a model in text-generation-webui is simple. Launch the webui by double-clicking the start_windows.bat script in your main ..."},"14":{y:0,u:"../Content/D_Model_configuration/Model_parameters.htm",l:-1,t:"Model parameters",i:0.176934011258778,a:"Unlike online services such as ChatGPT, Gemma or Claude, local LLMs offer you the possibility of manually adjusting their parameters. You can make the AI\u0027s responses more or less random and predictable, change the output length and more. Instruction templates Instruction templates are a template for ..."},"15":{y:0,u:"../Content/D_Model_configuration/Generation_parameters.htm",l:-1,t:"Generation parameters",i:0.01071716486631,a:"Generation parameters Delete this text and replace it with your own content."},"16":{y:0,u:"../Content/E_Chatting/Chatting.htm",l:-1,t:"Chatting",i:0.161110115820312,a:"If you\u0027ve been following the guide so far, your local model should be ready to interact with. As a reminder, here are the steps you should have taken so far:  You should have a  local installation of text-generation-webui You  chose a model  and  downloaded it You\u0027ve successfully  loaded the model  ..."},"17":{y:0,u:"../Content/E_Chatting/Basic_chats.htm",l:-1,t:"Basic chats",i:0.0335429369971039,a:"To chat with your AI assistant using text-generation-webui, navigate to the Chat tab.  Caution! If you closed the application at any time during the configuration process, you will have to reload the model.  You will see the main interface: Main toolbar: contains various tabs - most importantly ..."},"18":{y:0,u:"../Content/E_Chatting/Characters.htm",l:-1,t:"Characters",i:0.0202198573243863,a:"While chatting with your AI assistant is fun on its own right, you may also wish to breathe some character into your chats. Text-generation-webui offers a characters feature, allowing the AI assistant to play any role you can imagine. Load a model, then navigate to Parameters \u003e Character.  You will ..."},});